{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport matplotlib.pyplot as plt\nimport torchvision\nimport csv\nimport glob\nimport cv2\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom random import shuffle\nimport glob\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train', 'test']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 50, 5)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        \n        self.conv2 = nn.Conv2d(50, 100, 7)\n        self.pool2 = nn.MaxPool2d(2,2)\n        \n        self.fc1 = nn.Linear(100 * 12 * 12, 120)\n        self.fc2 = nn.Linear(120, 100)\n        self.fc3 = nn.Linear(100, 2)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = x.view(100, 100 * 12 * 12)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nprint(net)",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Net(\n  (conv1): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(50, 100, kernel_size=(7, 7), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=14400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=2, bias=True)\n)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea60325659022aecf79f1e98337f707420915c2a"
      },
      "cell_type": "code",
      "source": "'''\n#alternate way to create a list of file name and labels\n\nimport numpy as np\nimport os\nPATH = '../input/'\nfnames = np.array([f'train/{f}' for f in sorted(os.listdir(f'{PATH}train'))])\nlabels = np.array([(0 if 'cat' in fname else 1) for fname in fnames])\nprint(fnames[0:100] , labels[0:100])\n'''",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "\"\\n#alternate way to create a list of file name and labels\\n\\nimport numpy as np\\nimport os\\nPATH = '../input/'\\nfnames = np.array([f'train/{f}' for f in sorted(os.listdir(f'{PATH}train'))])\\nlabels = np.array([(0 if 'cat' in fname else 1) for fname in fnames])\\nprint(fnames[0:100] , labels[0:100])\\n\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "227e1c27c6b396582927b65f486ccd4373c9a58d"
      },
      "cell_type": "code",
      "source": "    shuffle_data = True  # shuffle the addresses before saving\n    cat_dog_train_path = '../input/train/*.jpg'\n    # read addresses and labels from the 'train' folder\n    addrs = glob.glob(cat_dog_train_path)\n    labels = [ [1,0] if 'cat' in addr else [0,1] for addr in addrs]  # 1 = Cat, 0 = Dog\n    # to shuffle data\n    if shuffle_data:\n        c = list(zip(addrs, labels))\n        shuffle(c)\n        addrs, labels = zip(*c)\n        print(labels[0:10])\n        \n    # Divide the hata into 60% train, 20% validation, and 20% test\n    train_addrs = addrs[0:int(0.6*len(addrs))]\n    train_labels = labels[0:int(0.6*len(labels))]\n    \n    val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n    val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n    \n    test_addrs = addrs[int(0.8*len(addrs)):]\n    test_labels = labels[int(0.8*len(labels)):]\n    \n    ",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "([1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 1], [1, 0], [1, 0], [0, 1], [1, 0])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "113a254a5f566385e41e16ab9148d042deaabb43"
      },
      "cell_type": "code",
      "source": "    # loop over train addresses\n    train_data = []\n    for i in range(len(train_addrs[:100])):\n        # print how many images are saved every 10 images\n        if i % 10 == 0 and i > 1:\n            print ('Train data: {}/{}'.format(i, len(train_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = train_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        train_data.append([np.array(img), np.array(train_labels[i])])\n    shuffle(train_data)\n    np.save('train_data.npy', train_data)\n    \n    \n    \n    \n    \n     # loop over test addresses\n    #creating test data\n    test_data = []\n    for i in range(len(test_addrs[:10])):\n        # print how many images are saved every 10 images\n        if i % 9 == 0 and i > 1:\n            print ('Test data: {}/{}'.format(i, len(test_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = test_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        test_data.append([np.array(img), np.array(labels[i])])\n    shuffle(test_data)\n    np.save('test_data.npy', test_data)\n    \n    \n    \n    # loop over val addresses\n    val_data = []\n    for i in range(len(val_addrs[:10])):\n        # print how many images are saved every 1000 images\n        if i % 9 == 0 and i > 1:\n            print ('Val data: {}/{}'.format(i, len(val_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = val_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        val_data.append([np.array(img), np.array(labels[i])])\n    shuffle(val_data)\n    np.save('val_data.npy', val_data)\n    #print(val_data[1])",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train data: 10/15000\nTrain data: 20/15000\nTrain data: 30/15000\nTrain data: 40/15000\nTrain data: 50/15000\nTrain data: 60/15000\nTrain data: 70/15000\nTrain data: 80/15000\nTrain data: 90/15000\nTest data: 9/5000\nVal data: 9/5000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96099c17dec163b9e5a9b5aa39d31c7a4f61e1e5"
      },
      "cell_type": "code",
      "source": "X = np.array([i[0] for i in train_data]).reshape(-1,64,64,3)\nX = Variable(torch.Tensor(X))\nX = X.reshape(-1,64,64,3)\nX = X.permute(0,3,1,2)\nprint(X.shape)\n#Y = Variable(torch.Tensor(Y))\n\nY = np.array([i[1] for i in train_data])\ntarget = Variable(torch.Tensor(Y))\ntarget = target.type(torch.LongTensor)\n\nprint(target.shape)\n#print(target)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.Size([100, 3, 64, 64])\ntorch.Size([100, 2])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3056071126e609a4eeef182f5e32bb7c2b00e3de"
      },
      "cell_type": "code",
      "source": "criterian = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "535d4fb839f19fe619dc01482a08b23f1e887c63"
      },
      "cell_type": "code",
      "source": "for epoch in range(50):\n    running_loss  = 0.0\n    optimizer.zero_grad() #zero the parameter gradients\n    output = net(X)\n    \n    loss = criterian(output, torch.max(target, 1)[1])\n    \n    loss.backward()\n    optimizer.step()\n    running_loss += loss.item()\n    print(epoch, ':', running_loss)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0 : 0.5776050686836243\n1 : 0.5661248564720154\n2 : 0.5801392197608948\n3 : 0.5620978474617004\n4 : 0.5984208583831787\n5 : 0.5227671265602112\n6 : 0.7208433747291565\n7 : 0.6681722402572632\n8 : 0.606266438961029\n9 : 0.669844388961792\n10 : 0.6182984709739685\n11 : 0.6257927417755127\n12 : 0.591269314289093\n13 : 0.5433756113052368\n14 : 0.5522409081459045\n15 : 0.5264785885810852\n16 : 0.5046387910842896\n17 : 0.5025985836982727\n18 : 0.45203158259391785\n19 : 0.4514327645301819\n20 : 0.4102950692176819\n21 : 0.3642967939376831\n22 : 0.36216259002685547\n23 : 0.46287572383880615\n24 : 0.5876555442810059\n25 : 0.34287455677986145\n26 : 0.38832196593284607\n27 : 0.3615037798881531\n28 : 0.3143447935581207\n29 : 0.26958781480789185\n30 : 0.25282952189445496\n31 : 0.3968141973018646\n32 : 1.4204814434051514\n33 : 1.2849116325378418\n34 : 0.5022835731506348\n35 : 0.5432926416397095\n36 : 0.5501907467842102\n37 : 0.5478646159172058\n38 : 0.5186842083930969\n39 : 0.47836101055145264\n40 : 0.44548577070236206\n41 : 0.42268794775009155\n42 : 0.3912109136581421\n43 : 0.36280372738838196\n44 : 0.34003525972366333\n45 : 0.31031373143196106\n46 : 0.2824307084083557\n47 : 0.24617700278759003\n48 : 0.20897501707077026\n49 : 0.18348641693592072\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a65cabe1a0cc2bba6bb101c07535a69240959ba9"
      },
      "cell_type": "code",
      "source": "test = np.array([i[0] for i in test_data]).reshape(-1,64,64,3)\ntest = Variable(torch.Tensor(test))\ntest = test.reshape(-1,64,64,3)\ntest = test.permute(0,3,1,2)\nprint(test.shape)\n#Y = Variable(torch.Tensor(Y))\n\ntlabels = np.array([i[1] for i in test_data])\ntlabels = Variable(torch.Tensor(tlabels))\ntlabels = tlabels.type(torch.float)\n\nprint(tlabels.shape)\nprint(tlabels)",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.Size([10, 3, 64, 64])\ntorch.Size([10, 2])\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [0., 1.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [0., 1.]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67f555608d40f47fef29701e90ff4e1d10bce6d8"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a34cf9b18d8e63e69095ea4c801700712ca1ffc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b4676ffdc24aaf40a533a4970fe1402c9cd25ba"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c74e6269caa18b3d2e140bbb77746ebfe25d6bc1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8e828772e550c9b586cb950494407249201ad17"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ac89e7678172b21d95dacf31135d1763176ae36"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73dad748e625c14c3c28de93320262fc187fee19"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba2c9b2864f97e9f3ab745a1625b7b10ba346d2a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}