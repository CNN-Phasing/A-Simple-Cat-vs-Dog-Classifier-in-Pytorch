{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport matplotlib.pyplot as plt\nimport torchvision\nimport csv\nimport glob\nimport cv2\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom random import shuffle\nimport glob\n#from torchsummary import summary\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['sample_submission.csv', 'train', 'test']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9acc972e27980e9dd92bb919c0aa5d9b46d0d663"
      },
      "cell_type": "code",
      "source": "\n#classes = ('plane', 'car', 'bird', 'cat',\n#          'deer', 'dog', 'frog', 'horse', 'ship', 'truck')",
      "execution_count": 62,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 50, 5)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        \n        self.conv2 = nn.Conv2d(50, 100, 7)\n        self.pool2 = nn.MaxPool2d(2,2)\n        \n        self.fc1 = nn.Linear(100 * 12 * 12, 120)\n        self.fc2 = nn.Linear(120, 100)\n        self.fc3 = nn.Linear(100, 2)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = x.view(-1, 100 * 12 * 12)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.sigmoid(self.fc3(x))\n        return x\n\nnet = Net()\nprint(net)",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Net(\n  (conv1): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(50, 100, kernel_size=(7, 7), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=14400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=2, bias=True)\n)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43590c4b5e5b317549f0aaf541a312a3fadc360f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea60325659022aecf79f1e98337f707420915c2a"
      },
      "cell_type": "code",
      "source": "'''\n#alternate way to create a list of file name and labels\n\nimport numpy as np\nimport os\nPATH = '../input/'\nfnames = np.array([f'train/{f}' for f in sorted(os.listdir(f'{PATH}train'))])\nlabels = np.array([(0 if 'cat' in fname else 1) for fname in fnames])\nprint(fnames[0:100] , labels[0:100])\n'''",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "\"\\n#alternate way to create a list of file name and labels\\n\\nimport numpy as np\\nimport os\\nPATH = '../input/'\\nfnames = np.array([f'train/{f}' for f in sorted(os.listdir(f'{PATH}train'))])\\nlabels = np.array([(0 if 'cat' in fname else 1) for fname in fnames])\\nprint(fnames[0:100] , labels[0:100])\\n\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "227e1c27c6b396582927b65f486ccd4373c9a58d"
      },
      "cell_type": "code",
      "source": "    shuffle_data = True  # shuffle the addresses before saving\n    cat_dog_train_path = '../input/train/*.jpg'\n    # read addresses and labels from the 'train' folder\n    addrs = glob.glob(cat_dog_train_path)\n    labels = [ [1,0] if 'cat' in addr else [0,1] for addr in addrs]  # 1 = Cat, 0 = Dog\n    # to shuffle data\n    if shuffle_data:\n        c = list(zip(addrs, labels))\n        shuffle(c)\n        addrs, labels = zip(*c)\n        print(labels[0:10])\n        \n    # Divide the hata into 60% train, 20% validation, and 20% test\n    train_addrs = addrs[0:int(0.6*len(addrs))]\n    train_labels = labels[0:int(0.6*len(labels))]\n    #train_addrs.size\n    \n    val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n    val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n    \n    test_addrs = addrs[int(0.8*len(addrs)):]\n    test_labels = labels[int(0.8*len(labels)):]\n    \n    ",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": "([0, 1], [1, 0], [1, 0], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1], [1, 0], [1, 0])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "113a254a5f566385e41e16ab9148d042deaabb43"
      },
      "cell_type": "code",
      "source": "    # loop over train addresses\n    train_data = []\n    for i in range(len(train_addrs[:1000])):\n        # print how many images are saved every 10 images\n        if i % 1000 == 0 and i > 1:\n            print ('Train data: {}/{}'.format(i, len(train_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = train_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        train_data.append([np.array(img), np.array(train_labels[i])])\n    shuffle(train_data)\n    np.save('train_data.npy', train_data)\n    \n    \n    \n    \n    \n     # loop over test addresses\n    #creating test data\n    test_data = []\n    for i in range(len(test_addrs[:1000])):\n        # print how many images are saved every 1000 images\n        if i % 1000 == 0 and i > 1:\n            print ('Test data: {}/{}'.format(i, len(test_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = test_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        test_data.append([np.array(img), np.array(labels[i])])\n    shuffle(test_data)\n    np.save('test_data.npy', test_data)\n    \n    \n    \n    # loop over val addresses\n    val_data = []\n    for i in range(len(val_addrs[:1000])):\n        # print how many images are saved every 1000 images\n        if i % 1000 == 0 and i > 1:\n            print ('Val data: {}/{}'.format(i, len(val_addrs)))\n        # read an image and resize to (64, 64)\n        # cv2 load images as BGR, convert it to RGB\n        addr = val_addrs[i]\n        img = cv2.imread(addr)\n        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        val_data.append([np.array(img), np.array(labels[i])])\n    shuffle(val_data)\n    np.save('val_data.npy', val_data)\n    #print(val_data[1])",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96099c17dec163b9e5a9b5aa39d31c7a4f61e1e5"
      },
      "cell_type": "code",
      "source": "from torch.autograd import Variable\nX = np.array([i[0] for i in train_data]).reshape(-1,64,64,3)\nX = Variable(torch.Tensor(X))\nX = X.reshape(-1,64,64,3)\nX = X.permute(0,3,1,2)\nprint(X.shape)\n#Y = Variable(torch.Tensor(Y))\n\nY = np.array([i[1] for i in train_data])\ntarget = Variable(torch.Tensor(Y))\ntarget = target.type(torch.LongTensor)\n\nprint(target.shape)\n#print(target)",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.Size([1000, 3, 64, 64])\ntorch.Size([1000, 2])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3056071126e609a4eeef182f5e32bb7c2b00e3de"
      },
      "cell_type": "code",
      "source": "criterian = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "535d4fb839f19fe619dc01482a08b23f1e887c63",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "for epoch in range(100):\n    running_loss  = 0.0\n    optimizer.zero_grad() #zero the parameter gradients\n    output = net(X)\n    \n    loss = criterian(output, torch.max(target, 1)[1])\n    \n    loss.backward()\n    optimizer.step()\n    running_loss += loss.item()\n    print(epoch, ':', running_loss)",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "0 : 0.7065433263778687\n1 : 0.7014573216438293\n2 : 0.6957210898399353\n3 : 0.6923933029174805\n4 : 0.6914113759994507\n5 : 0.6915519833564758\n6 : 0.6919784545898438\n7 : 0.6923094391822815\n8 : 0.6924932599067688\n9 : 0.6925349831581116\n10 : 0.6924546957015991\n11 : 0.6922893524169922\n12 : 0.6920660138130188\n13 : 0.6917970776557922\n14 : 0.6914887428283691\n15 : 0.6911299228668213\n16 : 0.6907241344451904\n17 : 0.6902555823326111\n18 : 0.6897157430648804\n19 : 0.6890643239021301\n20 : 0.6882694959640503\n21 : 0.6872979998588562\n22 : 0.6861180663108826\n23 : 0.6846662759780884\n24 : 0.6828793287277222\n25 : 0.6806977987289429\n26 : 0.6781398057937622\n27 : 0.675240159034729\n28 : 0.672492265701294\n29 : 0.6702548265457153\n30 : 0.668377161026001\n31 : 0.6659526228904724\n32 : 0.6631215214729309\n33 : 0.6611957550048828\n34 : 0.6598941087722778\n35 : 0.6580750942230225\n36 : 0.6558840870857239\n37 : 0.6541180610656738\n38 : 0.652590274810791\n39 : 0.6504700183868408\n40 : 0.6479725241661072\n41 : 0.6458150148391724\n42 : 0.6438727378845215\n43 : 0.6417132019996643\n44 : 0.6397854685783386\n45 : 0.638364851474762\n46 : 0.6369372606277466\n47 : 0.6354094743728638\n48 : 0.6341707110404968\n49 : 0.6328492760658264\n50 : 0.6312226057052612\n51 : 0.6296876072883606\n52 : 0.6282459497451782\n53 : 0.6267107725143433\n54 : 0.6253554224967957\n55 : 0.6241924166679382\n56 : 0.6229360103607178\n57 : 0.6217370629310608\n58 : 0.6205650568008423\n59 : 0.6192552447319031\n60 : 0.61798095703125\n61 : 0.616779088973999\n62 : 0.615537703037262\n63 : 0.6143873929977417\n64 : 0.6133056879043579\n65 : 0.6121909022331238\n66 : 0.6110978126525879\n67 : 0.6099660396575928\n68 : 0.6088104248046875\n69 : 0.6077243685722351\n70 : 0.6066458821296692\n71 : 0.6056051850318909\n72 : 0.6046038866043091\n73 : 0.603563129901886\n74 : 0.6025543212890625\n75 : 0.6015393733978271\n76 : 0.6005120873451233\n77 : 0.599507749080658\n78 : 0.5984795093536377\n79 : 0.5974869728088379\n80 : 0.5965243577957153\n81 : 0.59555584192276\n82 : 0.5946058034896851\n83 : 0.5936659574508667\n84 : 0.5927397608757019\n85 : 0.5918466448783875\n86 : 0.5909472107887268\n87 : 0.5900576710700989\n88 : 0.5891637802124023\n89 : 0.5882807970046997\n90 : 0.5874122381210327\n91 : 0.5865622162818909\n92 : 0.5857247710227966\n93 : 0.584886372089386\n94 : 0.5840503573417664\n95 : 0.5832145810127258\n96 : 0.5823981761932373\n97 : 0.5815994739532471\n98 : 0.5808214545249939\n99 : 0.5800585150718689\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a65cabe1a0cc2bba6bb101c07535a69240959ba9"
      },
      "cell_type": "code",
      "source": "test = np.array([i[0] for i in test_data]).reshape(-1,64,64,3)\ntest = Variable(torch.Tensor(test))\ntest = test.reshape(-1,64,64,3)\ntest = test.permute(0,3,1,2)\nprint(test.shape)\n#Y = Variable(torch.Tensor(Y))\n\ntlabels = np.array([i[1] for i in test_data])\ntlabels = Variable(torch.Tensor(tlabels))\ntlabels = tlabels.type(torch.long)\n\nprint(tlabels.shape)\nprint(tlabels)",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": "torch.Size([1000, 3, 64, 64])\ntorch.Size([1000, 2])\ntensor([[1, 0],\n        [0, 1],\n        [0, 1],\n        ...,\n        [0, 1],\n        [0, 1],\n        [1, 0]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ede18d752d9f240a17228fb6800abc4f61121d6"
      },
      "cell_type": "code",
      "source": "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in zip(X,target):\n        images, labels = data\n        images = images.reshape(1,3,64,64)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        #total += labels.size(0)\n        if((predicted == 0 and labels[0] == 1) or (predicted == 1 and labels[1]==1) ):\n            correct+=1\n        #correct += (predicted == labels).sum().item()\n        #print(outputs,labels)\ntotal = X.shape[0]\nprint('Train accuracy of the network on the' + str(total) +  'train images: %f %%' % (\n    100 * (correct*1.0) / total) )\nprint(correct, total)",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Train accuracy of the network on the1000train images: 75.500000 %\n755 1000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67f555608d40f47fef29701e90ff4e1d10bce6d8"
      },
      "cell_type": "code",
      "source": "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in zip(test,tlabels):\n        images, labels = data\n        images = images.reshape(1,3,64,64)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        #total += labels.size(0)\n        if((predicted == 0 and labels[0] == 1) or (predicted == 1 and labels[1]==1) ):\n            correct += 1\n            \ntotal = test.shape[0]\nprint('Test accuracy of the network on the ' + str(total) +  ' test images: %f %%' % (\n    100 * (correct*1.0) / total) )\nprint(correct, total)",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Test accuracy of the network on the 1000 test images: 53.600000 %\n536 1000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1bb30c2689c33e44830cdd472e9e474ed7872b51"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}